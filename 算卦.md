## OS

#### 1.五种IO模型

阻塞IO，非阻塞IO，IO多路复用，信号驱动式IO，异步非阻塞IO

**阻塞IO**：如果accept队列为空，导致用户进程sleep，交出cpu，发生进程间切换

**非阻塞IO**：如果accept队列为空，内核收到系统调用，再收到进程的read操作后，未完成不会阻塞会返回一个error；用户进程需要不断的主动询问kernel数据准备好了没有；不会交出CPU，造成严重的资源耗费

**IO多路复用：**select，poll，epoll 一个线程保存多个socket，轮询监控读写IO。虽然会发生阻塞但不会阻塞在io上，是阻塞在函数上。一个socket的阻塞不会影响其他的socket的Io读写。

最大的优势是：一个用户线程监控多个socket io

**信号驱动式IO：**首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，用户进程再调用I/O操作函数处理数据。

**异步非阻塞IO：**异步IO不是顺序执行。`用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情`。等到socket数据准备好了，内核直接复制数据给进程无序用户进程调用IO操作，`然后从内核向进程发送通知`。`IO两个阶段，进程都是非阻塞的`。

#### 2.select/poll/epoll的区别

|              | select                                                       | poll                   | epoll                                       |
| ------------ | ------------------------------------------------------------ | ---------------------- | ------------------------------------------- |
| 打开句柄数量 | 句柄集合是一个数组，调用select需要全部拷贝，内核做了限制1024 | 用链表储存没有大小限制 | 一个文件描述符管理多个描述符,数量远大于1024 |
| 内存         | 每次调用select，都需要把`fd_set`集合从用户态拷贝到内核       | 和select一样           | Mmap内存映射和内核共用一块内存              |
| 操作         | 内核要对所有fd_set进行遍历，如果`fd_set`集合很大时，那这个开销也很大， | 和select一样           | 活跃的socket才会触发                        |

#### 3. 进程，线程和协程

##### 进程

进程是系统分配资源的最小单位，所以进程和进程间的内存是相互隔离的并不共享。在进程未占用处理器时，进程 的上下文是存储在进程的私有[堆栈](https://baike.baidu.com/item/堆栈)中的；切换时要保存当前进程的上下文；所以频繁切换进程需要整理一大段内存空间来保存未执行完的进程现场，等下次轮到 CPU 时间片再恢复现场进行运算。频繁切换会带来大小的资源消耗。

##### 线程（内核级线程）

由内核进行调度，共享进程的内存空间，切换自然；但是数量过多会对内核的调度器带来不小的负担，甚至拖垮整体性能。

##### 协程（用户级线程）

是一个特殊的用户函数，可以挂起和恢复运行，完全由用户程序来进行调度，但是在一个线程内并不能并发执行，只能是线性，这就意味着只要有一个阻塞占用CPU资源就会造成所有线程的阻塞。想并发还得依靠多个线程。但是胜在内存共享，切换成本极低。

#### 4.线程模型

* 用户级线程 1:N
* 内核级线程 1:1
* 两极线程模型 M:N

#### 5.GC

#####  1>引用计数法

在一个对象被引用的时候，对象引用计数器加1，为0必定被当成垃圾回收

优点:渐进式分散在整个系统流程中，不会产生STW;简单

缺点:每次GC都要变更计数器以及维护计数器的空间；循环引用问题无法处理；

##### 2>标记清除

分为标记和清除两步；

标记: Collector从引用根结点开始遍历,标记所有被引用的对象。一般是在对象的Header中记录为可达对象。

清除: Collector对堆内存从头到尾进行线性的遍历,如果发现某个对象在其Header中没有标记为可达对象,则将其回收。

缺点:标记阶段需要STW才能准确的定位；清除阶段不移动内存，可能会产生较多的垃圾碎片

##### 3>复制收集

基于标记清除的升级，内存一分为2，标记玩将存活的复制的另一块内存中，然后清除原空间

优点：没有内存碎片效率高

缺点: 会浪费一半内存

##### 4>标记整理

和标记-清除算法类似，多了一步 存活的变量向一端移动，直接清理掉边界以外的内存

##### 5>并发标记清除（concurrency mark sweep）CMS

主要目的是减少标记阶段的STW；

与用户程序一起并发;

将产生的用户产生的新对象或者修改的对象记录下来STW重新标记；

1.初始标记，这个阶段是标记根对象(全局对象和线程栈上的对象)。其中标记全局对象要STW，标记线程栈只需要暂停目标线程

2.并发标记，并发遍历根对象的引用对象

3.重新标记，是重新标记在阶段2发生表更的对象，需要STW保证一致性；

4.并发清除

缺点：没有解决内存碎片的问题；会拉长GC的时间并且占用CPU资源

##### 6>三色标记

对标记-清除 标记阶段进行改进
白色：尚未访问过。
黑色：本对象已访问过，而且本对象 引用到 的其他对象 也全部访问过了。
灰色：本对象已访问过，但是本对象 引用到 的其他对象 尚未全部访问完。全部访问后，会转换为黑色

1.所有对象都是白色。
2.从根出发扫描所有可达对象，标记为灰色，放入待处理队列。
3.从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。
4.重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。

优点：还是对STW的优化，以及缩短GC流程

##### 7>分代收集(不是垃圾算法是一种GC的策略)

根据对象存活周期的不同将内存划分为几块，一般是划分为新生代和老年代。
在新生代发现有大批对象死去就采用复制算法，只需要付出少量存活对象的复制成本。
老年代中对象存活率高 没有额外空间对它进行分配担保，就使用标记整理 或者 标记清除 或者CMS

## 网络

#### 1. 常用状态码

301 永久重定向

302 重定向，禁止缓存

304  （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。

401（未授权） 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应

403  （禁止） 服务器拒绝请求。-权限校验

412  （未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。

413  请求实体过大

500 服务内部发生错误-**服务发生错误**

502 与上游未成功建立连接

503 服务暂时不可用-**发生在nginx限流**

504 错误代表网关超时 （Gateway timeout），是指[服务器](https://baike.baidu.com/item/服务器/100571)作为网关或代理，但是没有及时从上游服务器收到请求。服务器（不一定是 Web 服务器）正在作为一个网关或代理来完成客户访问所需网址的请求。 为了完成您的 HTTP 请求， 该服务器访问一个上游服务器， 但没得到及时的响应。- **通常发生在上游超时或者关闭**

#### 2. TCP三次握手

客户端主动发起请求会发送一个SYN报文初始序号seq这就是第一次握手，服务器收到后返回一段SYN,ACK报文以及带着自己的初始序列号这是第二次握手，最后客户端返回一个ACK 确认收到收到初始序列号。

##### 不是两次握手的原因

双方都需要确认对方的初始序列号，所以在保证消耗资源最小和保证安全的前提下3次最合适

##### 不主动关闭连接的保活

TCP设有一个保活计时器，服务器每收到一次客户端的请求都会重新复位这个计时器，时间通常设置为两小时，如果两个小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，每隔75秒发送一次。如果一连发送10个探测报文仍然没有反应，服务器认为客户端出了故障，接着就关闭连接

#### 4.TCP 关闭连接的四次挥手

第一次挥手:发送一个FIN带着自己序号seq，表示想要断开连接，进入FIN_WAIT_1（半关闭状态）

第二次挥手:服务器收到后离开ESTABLISHED状态，进入close_wait, 返回ACK 确认自己收到了关闭的请求并检查自己是否还有数据要发送给主动方，客户端进入FIN-WAIT-2

第三次挥手:服务器开始向客户端发送FIN，ACK(表示在收到客户端报文的基础上+1)表示已经准备好释放连接，进入last-ack

第四次挥手:  客户端发送ACK表示收到，进入TIME_WAIT

##### 为什么是四次

服务器接收到请求后，有可能还有未处理完成的请求。

和握手一样是基于seq和ack来做的，双方都需要知道对方收到自己的请求，一但都是报文流程就不可继续

##### 为什么要time_wait等待2MSL（max segment lifetime一段TCP报文在传输过程中的最长生命周期）

这是一个保底机制，最后一次挥手客户端不确定服务器会不会收到报文。

而服务器在1MSL内没有收到ACK报文，就会向客户端重新发送一个ACK报文

#### 3. TCP的状态

**CLOSED**：初始状态，表示TCP连接是“关闭着的”或“未打开的”。

**LISTEN** ：表示服务器端的某个SOCKET处于监听状态，可以接受客户端的连接。

**SYN_RCVD** ：表示服务器接收到了来自客户端请求连接的SYN报文。在正常情况下，这个状态是服务器端的SOCKET在建立TCP连接时的三次握手会话过程中的一个中间状态，很短暂，基本上用netstat很难看到这种状态，除非故意写一个监测程序，将三次TCP握手过程中最后一个ACK报文不予发送。当TCP连接处于此状态时，再收到客户端的ACK报文，它就会进入到ESTABLISHED 状态。

**SYN_SENT** ：这个状态与SYN_RCVD 状态相呼应，当客户端SOCKET执行connect()进行连接时，它首先发送SYN报文，然后随即进入到SYN_SENT 状态，并等待服务端的发送三次握手中的第2个报文。SYN_SENT 状态表示客户端已发送SYN报文。

**ESTABLISHED** ：表示TCP连接已经成功建立。

**FIN_WAIT_1** ：这个状态得好好解释一下，其实FIN_WAIT_1 和FIN_WAIT_2 两种状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：

FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET进入到FIN_WAIT_1 状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2 状态。当然在实际的正常情况下，无论对方处于任何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1 状态一般是比较难见到的，而FIN_WAIT_2 状态有时仍可以用netstat看到。

**FIN_WAIT_2** ：上面已经解释了这种状态的由来，实际上FIN_WAIT_2状态下的SOCKET表示半连接，即有一方调用close()主动要求关闭连接。注意：FIN_WAIT_2 是没有超时的（不像TIME_WAIT 状态），这种状态下如果对方不关闭（不配合完成4次挥手过程），那这个 FIN_WAIT_2 状态将一直保持到系统重启，越来越多的FIN_WAIT_2 状态会导致内核crash。

**TIME_WAIT** ：表示收到了对方的FIN报文，并发送出了ACK报文。 TIME_WAIT状态下的TCP连接会等待2*MSL（Max Segment Lifetime，最大分段生存期，指一个TCP报文在Internet上的最长生存时间。每个具体的TCP协议实现都必须选择一个确定的MSL值，RFC 1122建议是2分钟，但BSD传统实现采用了30秒，Linux可以cat /proc/sys/net/ipv4/tcp_fin_timeout看到本机的这个值），然后即可回到CLOSED 可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（这种情况应该就是四次挥手变成三次挥手的那种情况）

**CLOSING** ：这种状态在实际情况中应该很少见，属于一种比较罕见的例外状态。正常情况下，当一方发送FIN报文后，按理来说是应该先收到（或同时收到）对方的ACK报文，再收到对方的FIN报文。但是CLOSING 状态表示一方发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什么情况下会出现此种情况呢？那就是当双方几乎在同时close()一个SOCKET的话，就出现了双方同时发送FIN报文的情况，这是就会出现CLOSING 状态，表示双方都正在关闭SOCKET连接。

**CLOSE_WAIT** ：表示正在等待关闭。怎么理解呢？当对方close()一个SOCKET后发送FIN报文给自己，你的系统毫无疑问地将会回应一个ACK报文给对方，此时TCP连接则进入到CLOSE_WAIT状态。接下来呢，你需要检查自己是否还有数据要发送给对方，如果没有的话，那你也就可以close()这个SOCKET并发送FIN报文给对方，即关闭自己到对方这个方向的连接。有数据的话则看程序的策略，继续发送或丢弃。简单地说，当你处于CLOSE_WAIT 状态下，需要完成的事情是等待你去关闭连接。

**LAST_ACK** ：当被动关闭的一方在发送FIN报文后，等待对方的ACK报文的时候，就处于LAST_ACK 状态。当收到对方的ACK报文后，也就可以进入到CLOSED 可用状态了。

#### 4. TIME_WAIT的问题

在高并发场景下，在短时间内业务处理+传输数据的时间远小于TIME_WAIT的时间，导致会有大量的端口被占用导致服务器拒绝为一部分客户服务。

编辑内核文件/etc/sysctl.conf

```
net.ipv4.tcp_syncookies = 1 表示开始SYN cookies, 当SYN等待队列溢出时，启用cookie来处理，可防范少量SYN攻击
net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认0，表示关闭
net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收 默认为0 表示关闭
net.ipv4.tcp_fin_timeout 修改系统默认的TIMEOUT时间
```

```
系统保存TIME_WAIT套接字的最大数量
```

#### 5.tcp和udp的区别

TCP通信协议

- TCP是面向连接的；
- 每条TCP连接只能由于两个端点，一对一通信；
- TCP提供可靠的交付服务，传输数据无差错，不丢失，不重复，且按时序到达；
- TCP提供全双工通信；
- 面向字节流，TCP根据对方给出的窗口和当前的网络拥塞程度决定一个报文应该包含多少个字节。

UDP通信协议

- 无连接；
- UDP使用尽最大努力交付，不保证可靠性UDP是面向报文的，UDP对应用层交付下来的报文，既不合并，也不拆分，而是保留报文的边界；
- 应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文；
- UDP没有拥塞控制；
- UDP支持一对一，一对多，多对一和多对多的交互通信。
- UDP的首部开销小，只有8字节。

#### 6.http(1 |1.1|2|3)的区别

##### http1.1  

1. TCP 连接复用-keep-alive

2. 请求需要满足**先进先出的队列顺序**：发送请求--等待响应，再发送下一个请求。HTTP/1.1允许多个http请求通过一个套接字同时被输出 ，而不用等待相应的响应。然后请求者就会等待各自的响应，这些响应是按照之前请求的顺序依次到达。（所有请求保持一个FIFO的队列，一个请求发送完之后，不必等待这个请求的响应被接受到，下一个请求就可以被再次发出；同时，服务器端返回这些请求的响应时也是按照FIFO的顺序）。- 这也叫队首阻塞

   由于TCP严格按照按顺序交付，丢失一个TCP分组就会阻塞所有高序号的分组，除非重传丢失的分组，这也会带来额外的延迟。由于HTTP1.1中不允许多路复用，HTTP管道也会带来一些不容忽视的问题：

   一个慢响应会阻塞所有后续请求；

   并行处理请求时，服务器需要缓存处理结果，会占用服务器资源，如果某个响应很大，很容易形成服务器的受攻击面；

   响应失败可能终止TCP连接，会强迫客户端重新发送对后续资源的请求，导致重复处理；

   网络环境中存在中间代理，检测管道兼容性十分必要；

   如果中间代理不支持管道，那它可能中断连接，也可能把所有请求串联起来。

   正是由于存在这样或那样的问题，HTTP管道技术的应用比较有限，并没有大面积推广开来，即使一些支持它的浏览器也仅仅把它作为一个高级选项。如果你对客户端和服务端都有很强的控制力，依然可以使用它，会带来不错的性能提升。

   优化：

   * 使用多个TCP连接

     **优点**：

     客户端可以并行发起多个请求；

     服务器可以并行处理多个请求；

     第一次往返可以发送的累计分组数量是原来的6倍；

     **缺点**：

     更多的套接字会占用更多的资源；

     并行TCP流之间竞争共享的带宽；

     处理多个套接字，实现更为复杂；

     即使并行TCP流，应用的并发能力也受限制。

     这种打开多个连接的方式，也带来了一些坏处，那为什么现在还使用的如此广泛呢？主要由以下三个原因:

     作为绕过HTTP限制的一个权宜之计；

     作为绕过TCP中低起始拥塞窗口的一个权宜之计；

     作为客户端绕过不能使用TCP窗口缩放的一个权益之计。

   * 域名分区绕一下：将N个域名指向同一台服务器上

3. 增强的缓存机制 没修改返回一个304 有改动返回一个200

4. **分块编码传输**

5. Host头域

6. **请求方式新增**

7. **带宽优化**

##### http2.0

在语义上保证稳定，语法上达到阔斧；仍然使用http和https；

* 优化了大头儿子header，头很大但是身体很小

  使用HPACK算法，在客户端和服务器两端建立“字典”，用索引号表示重复的字符串，还采用哈夫曼编码来压缩整数和字符串，可以达到50%～90%的高压缩率

* 二进制格式

  将原来的header+body的消息打散为数个小片的二进制帧，用headers帧存放头数据，data帧存放实体数据

* 虚拟流（可以看作http1的请求和响应）

  是一个二进制帧的双向传输序列，同一个消息往返的帧会分配一个唯一的流id。按照顺序组装起来就是就是请求和响应

* 多路复用

  HTTP/2可以在一个TCP连接上用“流”同时发送多个碎片化的消息--多个往返通信都复用一个TCP连接；

  在流层面是有序的

  在连接层面，消息乱序收发，多个请求和响应没有了顺序关系，所以也没有了队头阻塞。

* 服务器推送

  改变了传统意义上的“请求-应答”，服务器可以主动的新建一个流主动向客户端发送消息。（比如主动推送一些css和js）

* 强化了安全，将一些加密协议从白名单移除；通信协议需要在TLS1.2以上

##### http3

TCP为了保证有序性和完整性，当网络不好时，有个一个包未到达都会卡在TCP缓冲里。这就是TCP的队头阻塞。



#### 7.https

安全特性：机密性，完整性，身份认证，不可否认

在http和tcp/ip之间加了一层ssl/tls

密码套件：“密钥交换算法+签名算法+对称加密算法+摘要算法”

TLS 密钥交换使用非对称加密，之后的全部使用对称加密

数字签名生成数据摘要-SHA-2算法

#### 8.HPACK

静态表和动态表





## 数据结构（融化于各个细节中）

## 算法

## Nginx

#### 1.nginx如何处理一个请求

首先，nginx在启动时，会解析配置文件，得到需要监听的端口与ip地址，然后在nginx的master进程里面，先初始化好这个监控的socket(创建socket，设置addrreuse等选项，绑定到指定的ip地址端口，再listen)，然后再fork(一个现有进程可以调用fork函数创建一个新进程。由fork创建的新进程被称为子进程 )出多个子进程出来，然后子进程会竞争accept新的连接。此时，客户端就可以向nginx发起连接了。当客户端与nginx进行三次握手，与nginx建立好一个连接后，此时，某一个子进程会accept成功，得到这个建立好的连接的socket，然后创建nginx对连接的封装，即ngx_connection_t结构体。接着，设置读写事件处理函数并添加读写事件来与客户端进行数据的交换。最后，nginx或客户端来主动关掉连接，到此，一个连接就寿终正寝了。

　　当然，nginx也是可以作为客户端来请求其它server的数据的（如upstream模块），此时，与其它server创建的连接，也封装在ngx_connection_t中。作为客户端，nginx先获取一个ngx_connection_t结构体，然后创建socket，并设置socket的属性（ 比如非阻塞）。然后再通过添加读写事件，调用connect/read/write来调用连接，最后关掉连接，并释放ngx_connection_t。

　　nginx在实现时，是通过一个连接池来管理的，每个worker进程都有一个独立的连接池，连接池的大小是worker_connections。这里的连接池里面保存的其实不是真实的连接，它只是一个worker_connections大小的一个ngx_connection_t结构的数组。并且，nginx会通过一个链表free_connections来保存所有的空闲ngx_connection_t，每次获取一个连接时，就从空闲连接链表中获取一个，用完后，再放回空闲连接链表里面。

　　在这里，很多人会误解worker_connections这个参数的意思，认为这个值就是nginx所能建立连接的最大值。其实不然，这个值是表示每个worker进程所能建立连接的最大值，所以，一个nginx能建立的最大连接数，应该是worker_connections * worker_processes。当然，这里说的是最大连接数，对于HTTP请求本地资源来说，能够支持的最大并发数量是worker_connections * worker_processes，而如果是HTTP作为反向代理来说，最大并发数量应该是worker_connections * worker_processes/2。因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。

#### 2.负载均衡算法

轮询，最小连接，源地址hash

## mysql

#### 1.乐观锁和悲观锁

##### 悲观锁

* 适用于写多读少的情况，在修改数据之前先锁定防止被其他线程修改

* 具有强烈的独占和排他性。对数据被外界的修改持保守态度，在数据处理过程中，数据处于锁定状态。

* 悲观锁的实现依赖于数据库本身提供的锁机制；

* 对数据的修改持有悲观态度的并发控制方式。在每次读取数据的时候都默认有其他线程会更改数据，因此其他线程抗药访问数据时，都需要挂起。

类型：主要分为共享锁和排他锁

共享锁（读锁）：多个事务对同一数据可以共享一把锁，都可以访问数据，但是所有写操作会被阻塞包括自己

排他锁（写锁）：只能由一个事务获取，排斥其他读写锁，持有锁的线程可以读和修改

总：数据的访问都是先获取锁在处理，优点是保证数据安全；缺点是增加开销，降低并行性

##### 乐观锁

与悲观相对应，乐观是我们人类一种积极的情绪。**乐观锁的“乐观情绪”体现在，它认为数据的变动不会太频繁。因此，它允许多个事务同时对数据进行变动。** 但是，乐观不代表不负责，那么怎么去负责多个事务顺序对数据进行修改呢？乐观锁通常是通过在表中增加一个版本(version)或时间戳(timestamp)来实现，其中，版本最为常用。事务在从数据库中取数据时，会将该数据的版本也取出来(v1)，当事务对数据变动完毕想要将其更新到表中时，会将之前取出的版本v1与数据中最新的版本v2相对比，如果v1=v2，那么说明在数据变动期间，没有其他事务对数据进行修改，此时，就允许事务对表中的数据进行
修改，并且修改时version会加1，以此来表明数据已被变动。如果，v1不等于v2，那么说明数据变动期间，数据被其他事务改动了，此时不允许数据更新到表中，一般的处理办法是通知用户让其重新操作。不同于悲观锁，乐观锁是人为控制的。

#### 2.binlog

有三种模式：

Statement: 储存mysql原文；主备的索引选择不一致可能会导致主备不一致；

row：记录真实主库操作的数据，不会有主备不一的情况，缺点是占用资源，io量比较大

Mixed:statement和row的混合

#### 3.mysql中所有的日志名字

redo log

binlog

Relay log

#### 4.主备一致 双M M-S

#### 5.高可用

1.最终一致性：主库生成的所有的binlog都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性

2.主从切换-靠性优先策略 

判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；

把主库 A 改成只读状态，即把 readonly 设置为 true；

判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；把备库 B 改成可读写状态，也就是把 readonly 设置为 false；

把业务请求切到备库 B。

3.主从切换-可用性优先策略

#### 6.主备延迟

原因：

* 主备性能差异一主多从分担备库压力
* 大事务
* 大表DDL
* 并发高的不行

解决:

按表分发策略：两个事务操作不同表

按行分发策略：需要binlog row的支持

并行复制策略：粒度只支持到库

主备切换命令：

 ```
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
MASTER_LOG_FILE=$master_log_name 
MASTER_LOG_POS=$master_log_pos  
 ```

基于GTID执行主备切换：

```
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
master_auto_position=1 
```

##### 延迟问题解决方案：

强制走主库方案；

sleep 方案；（推到前端来做）

判断主备无延迟方案；

配合 semi-sync 方案；

等主库位点方案；

等 GTID 方案。

#### 7.误删数据

误删行：flushback 逆向执行binlog

误删库 / 表：需要定时备份，再增量binlog写入

预防误删库 / 表的方法：

总的来说预防比事后操作更加重要；

#### 10.sql优化

使用临时表的场景

1. 如果语句执行过程不可以一边读数据，一边直接得到结果，就需要额外的内存，来保存中间结果；

2. join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；

3. 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。

##### -----union语句的优化

语义取两子查询的交集，会用到临时表。建议改用union all

##### -----group by的优化

保证数据分组的有序性，不然容易产生使用内存临时表

```mysql
set tmp_table_size=1024;
select id%100 as m, count(*) as c from t1 group by m order by null limit 10;
```

**1>创建关联更新索引(5.7之后)**

```mysql
alter table t1 add column z int generated always as(id % 100), add index(z);
select z, count(*) as c from t1 group by z;
```

注：5.6以及之前版本可以创建普通索引来实现同样的功能，增加冗余列

**2>直接排序**

数据量特别大还是会使用内存临时表，直接使用磁盘，跳过多余的步骤,而且会优化成数据来存储

```mysql
select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;
```

##### -----join语句的优化

**使用小表作为驱动表**

在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。

**关联字段使用索引覆盖，否则会走全表扫描**

尤其是大表N*M,数据量过大超出buffer大小，会导致分段扫描

**不适合加索引的表的处理方式**

* 生成临时表

* 借助业务端代码 拆分sql（hash join）

  

**Multi-Range Read 优化(个人不太推介)**

MRR优化，目的是尽量使用磁盘顺序读写

因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能

```
set optimizer_switch="mrr_cost_based=off"
```

应用的场景：

MRR 能够提升性能的核心在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。

**Batched Key Access**

```
set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
```

我们就把表 t1 的数据取出来一部分，先放到一个临时内存join_buffer

#### 11.mysql对sql优化的一些数据结构

##### sort buffer

##### 内存临时表

上限为1024字节，超过上限就会导致转为磁盘储存默认使用Innodb，数据量小时使用memory

##### join buffer



## Redis

##### 1.Redis 缓存具体是怎么工作的？
##### 2.Redis 缓存如果满了，该怎么办？
##### 3.为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？
##### 4.Redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那么，Redis 缓存可以使用快速固态硬盘吗？

##### 5.Redis连接过高有1w个连接

有可能是大量socket连接之后迅速关闭造成的。

1.redis默认可以打来1w的连接，修改相关配置项,然后平滑重启

```
cd /usr/local/redis/bin 必须进入bin文件
./redis-server /usr/local/redis/etc/redis.conf  配置文件来启动Redis 服务
./redis-cli 启动客服端
127.0.0.1:6379>这个就代表进来了
debug reload 平滑重启
如果有密码就输入密码，密码忘记了就去Redis配置文件找
```

2.查看是否时空闲连接过多不释放

查看链接状态

```
redis-cli client list

addr=127.0.0.1:52555 fd=5 name= age=855 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client
addr=127.0.0.1:52787 fd=6 name= age=6 idle=5 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=ping
```

查看配置

```
redis-cli config get timeout
```

配置空闲清理

```
redis-cli config set timeout 600
```

3.修改业务代码使用连接池，避免每一个命令打开一个连接或者使用完后主动关闭

## Go&PHP

#### 1.GMP

M:工作线程和内核线程一一绑定

P:上线文

G:一个go函数，用户级线程

M与P是一对一的关系，经过调度也会进行P的切换，每个P下面有两个G队列， 一个是可运行G队列和运行完成的G队列；

但是P和M的数量不一定是相等的，当M由于系统调用发生阻塞，P下面的可运行G队列未空是会解绑的，会找到一个空闲的G或者新创建一个M

##### 关键的字段

runtime 全局G,M,P链表 

sched 调度器空闲P

​            调度器空闲G

​            调度器可运行G队列 环型队列

​			调度器两个自由G（有栈和无栈），为了复用都是空栈

​			本地运行G队列 上限256个的环型队列,满了之后会将其中的一半转移到全局可运行G队列中

​			本地自由G队列

##### 调度流程:

创建主G，调度中M与它绑定，后面执行

- 启动监控进程（由一个特殊的M执行）。
- 调用runtime的初始化函数。
- 开启gc。
- 调用main的初始化函数。
- 调用main.main，执行完后退出

##### 其中调度的流程为下：（运行在若干个M中，G的阻塞结束退出系统调用都会触发）

* 检查当前的M的绑定情况
  * 绑定则挂起并且停止调度
  * 没有绑定
* 判断有没有painc或者GC需要停止调度
* 开始寻找可运行的G
  * 全局可运行G，本地P
  * GC标记阶段的G
  * 从其他p中偷取G

* 有就看看有没有与M绑定，
  * 如果已绑定就唤醒
  * 执行

##### 系统监控干了啥

> 抢夺P和G: 

​	把可运行G放入全局可运行列表中；

​	通过网络IO轮询器获取可运行的G（即得到netpoller通知的G）；前提条件是以经过10ms没有按照此图径抢夺

​	从调度器里抢夺符合条件的G；

​	抢夺流程：

 * 判断P自身和系统监控的调用技术是否相同，相同就继续向下判断，不同更新备份并跳过

 * P处于Pruning和Psyscall

 * Psyscall:是否有必要抢夺P；P的G队列已空，有M处于自旋

   如果有符合条件的P，然后把P转给其他M

 * Pruning:超过10ms，发通知给G运行时间太长只负责发

> 是否强制GC,，唤醒GC的G

> 打印调度跟踪信息

#### 2.channle

共享信息的实现,原子操作。channle数据的传输本质上是数据的拷贝，通过lock来保证它的操作都是原子性的

#### 3.GC

##### 系统监测中的强制GC：

GC专用G一般处于暂停状态，只有系统监测可以恢复；

当当前GC未执行，且超过GC最大执行时间（2min），则唤醒并放入全局可运行G队列中；

清扫堆的工作只在距上次清扫时间大于最大时间间隔（5min），将最进未使用的堆内存还给操作系统；

##### 调度系统的自动GC：

多了一个条件，当占用内存有较大增量时才会触发(内存翻倍)

##### 具体流程:使用了三色标记的CMS

Go的垃圾回收官方形容为 **非分代 非紧缩 写屏障 并发标记清理**。

非分代是golang GC区别于JVM GC分代模型的特点；非紧缩意味着在回收垃圾的过程中，不需要像复制算法那样移动内存中的对象，这样避免STW过长；

标记清理算法的字面解释，就是将可达的内存块进行标记mark，最后没有标记的不可达内存块将进行清理sweep；Golang中实现标记功能的算法就是三色标记法，Golang里面三色标记法会造成错标问题，使用写屏障来解决这种问题，而JVM里面的CMS和G1解决错标或者漏标问题的算法分别是Increment Update和SATB

1. 从根结点开始遍历,根结点包括全局指针和goroutine栈上的指针；遍历全局需要STW，遍历goroutine只阻塞目标goroutine并打开写屏障。访问到的变为灰色，放入队列中
2. 并发遍历灰色队列，自身变黑，引用变为灰色放入队列知道队列变空；期间发生引用变更的都通过写屏障记录下来
3. 启动STW，重新扫描阶段2记录下来的数据
4. 并发清除不可达对象（白色）

##### STW的实现

1. 设置空闲p的状态为停止
2. 设置正在运行的G的抢占标志位，等待g主动停止运行，g的停止实际是发生系统调用/io阻塞/channle/函数调用

##### 写屏障 - 简单来说就是涂灰新使用的白色；记住这里的操作都是已经存在的内存

https://www.zhihu.com/question/62000722

- 强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象；

  插入写屏障：

 就是如果两个对象之间新建立引用，那么引用指向的对象就会被标记为灰色以满足强三色不变性，这是一种相对保守的屏障技术。

- 弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径

 删除写屏障：

  一个灰色对象指向一个白色对象的引用被删除，那么在删除之前写屏障检测到内存变化，就会把这个白色对象标灰。

![img](https://pic4.zhimg.com/50/v2-ba984b1dfd81dcdbd50cb91ebcf5d6d3_hd.jpg?source=1940ef5c)

#### 4.内存分配

#### 5.内存模型

#### 6.闭包语法

#### 7.go的并发控制

waitGroup｜

channle｜

context：

* WithValue 添加共享的消息 

* WithTimeOut设置超时时间
* Done 返回一个channle,会在当前工作完成或者上下文取消后关闭，多次调用返回同一个

* Err方法；Done后才会返回非空值

#### 8.data race数据竞争怎么解决

go命令自带的race命令，在构建代码时就可以检测

加锁

channle

#### 9.GRPC

#### 10.Go语言的优势

语法简单上手快

原生支持并发

部署简单，编译包小

实现微服务在性能，易用性和生态等方面都拥有优势

#### 11.Go kit

#### 12.select语句



## 综合问题

#### 1.json

#### 3.死锁的产生条件｜预防｜应急处理

##### 产生条件（原因）：

1.一个资源同时只能被一个线程占

2.一个线程因请求资源而阻塞时，对已获得的资源保持不放。

3.不能强制抢夺资源

4.若干个事务进程线程形成头尾相接的环状资源等待

##### 预防：

可以把资源一次性分配：（破坏请求和保持条件）

然后剥夺资源：即当某进程新的资源未满足时，释放已占有的资源（破坏不可剥夺条件）

资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）

代码中尽量早的释放锁资源

应急处理：

撤销一个环中的进程｜线程｜事务

#### 4.分布式锁（没有实践经验了解下就好）

分布式锁具备的条件：

1. 在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行；
2. 高可用的获取锁与释放锁；
3. 具备可重入特性；
4. 具备锁失效机制，防止死锁；
5. 具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败

基于redis的分布式锁：

基于数据库的分布式锁：

基于Zookeeper实现分布式锁：

ETCD的分布式锁：

## 消息队列

#### 1.rabbitMq和Kafka

## 微服务

#### 1.概念

laas 基础设施

paas 平台-阿里云

Saas 软件级服务

1.产品快速迭代，更快的上线速度

2.系统的高可用，故障时能够自动恢复与回滚

3.快速解决问题，细致的故障探测和发现

4.避免雪崩，故障时能自动隔离

5.系统的弹性伸缩，简便快速的水平扩容

运行层：指容器的基础设施，包括存储/网络/CPU等

编排层：主要指容器的管理，包括容器调度，服务注册与发现，资源管理

#### 2.DDD

领域驱动四层分层架构

用户表界面层（user interface）：展示

应用层（application）：负责逻辑整合 购物车清空，但是无业务逻辑

领域层（Domain）：封装业务逻辑

基础设施层：负责消息传输，基础数据储存

#### 3.服务网格

#### 4.微服务架构的复杂

服务注册与发现，协议转换，统一认真授权，负载均衡，分布式链路追踪，监控，故障处理和恢复，rpc调用，故障注入，动态路由请求

#### 5.微服务的演化

##### 单体架构

优点:所有软件都搭在一个机器上,部署简单明了

缺点:进行局部改动需要重新部署，而且编译时间过长

​         技术扩展不易，只能在原有基础上进行局部优化

##### 垂直分层架构

应用分为IO密集型和计算密集型，对架构进行分层。

缺点：垂直分层架构的系统拆分使得集群搭建变得复杂

​			设计到的服务间调用，服务间的耦合度便高，调用关系错综复杂，难以维护调用关系

##### SOA面向服务架构

向外提供服务，服务提供者，服务消费者（大公司向外提供服务）

##### 微服务

将业务系统彻底组件化和服务化

* 单一原则，每个微服务负责一个独立上下文边界
* 使用restful等轻量协议传输 
* 独立业务开发和活动周期
* 使用容器独立部署

缺点：

拆分过多也会造成一些问题，形成复杂的依赖链条

单个服务异常，其他依赖服务也会受到影响，出现服务雪崩效应

服务之间需要处理分布式事务，调用幂等性和重试等问题

开发成本高，对团队挑战大

##### 云原生

#### 6.Docker

虚拟化是在硬件上隔离应用，能够提供更好的资源隔离性，但是资源利用率比较高；

Docker是在操作系统上进行资源隔离，资源消耗低

能够将应用程序所需要的所有依赖，配置和环境变量打包成镜像，为应用程序提供运行环境。

**核心概念**

* 镜像

  镜像是由多个镜像叠加而成的文件系统，其底层为UnionFS与AUFS文件联合系统，这是一种分层，支持通过一层一层叠加的方式集成的轻量级且高性能文件系统。

  镜像只是一个只读的模版，可以在一个基础镜像上进行叠加，制作出多种多样不同的镜像。

* 容器

  通过镜像启动，是镜像的运行实例，一个镜像可以启动多个容器。容器之间相互隔离，它运行并隔离应用。

  容器可以被创建，运行，停止，删除，暂停和重启。可以简单将容器理解为应用程序提供沙箱运行环境的linux操作系统

* 仓库

  管理和存储镜像的地方，分为公有仓库和私有仓库

**基本命令**

1.检索docker

```
docker search redis
```

2.拉取镜像

```
doker pull redis:5.0
```

3.查看本地镜像列表

```
docker images redis
```

4.运行镜像

```
docker run -itd --name redis-5.0 -p 6379:6379 redis:5.0
```

-d 选项指定容器后台运行，启动返回容器的id

-i 让容器的标准输入保持打开

-t 让Dokcer分配一个伪终端并绑定到容器的标准输入上

--name 指定容器名

-p进行端口映射，容器端口:主机端口

5.查看本地运行的docker容器

```
docker ps
```

6.进入容器

```
docker exec -it redis-5.0(可以是name可以是id) /bin/bash 
```

7.构建自定义的容器Dockerfile

```dockerfile
FROM golang:latest
WORKDIR /root/micro-go-course/section10/user
COPY / /root/micro-go-course/section10/user
RUN go env -w XXXXX
RUN go build -o xxx
ENTRYPOINT ["./user"]
```

From 必须出现的第一个指令，用于指定基础镜像，在上述例子中我们指定了基础镜像为golang:latest版本

WORKDIR: 指定工作目录，之后的命令就会在改目录下运行

COPY：将本地文件添加到容器指定位置

RUN：创建镜像执行的命令

ENTRYPOINT 容器启动后被执行的命令

8.构建docker镜像

```
docker build -t user . #创建镜像
```

-t 用于指定镜像的名称和标签 名称:标签

.  dockerfile所在的文件位置

#### 7.k8s

Kubernetes是一个容器管理和编排系统

有两类节点组成

* master节点 主要负责管理和控制，调度中心
  * API Server 
  * scheduler
  * controller
  * Etcd
* Node节点
  * pod 创建和部署的基本单位，代表了集群中运行的一个进程，内部由一个或者多个共享资源的容器组成，可以简单理解成一台虚拟主机；
  * docker，是pod中最常见的容器runtime
  * Kubelet 负责维护调度到它所在Node节点的Pod的生命周期，包括创建修改删除和监控
  * kube-proxy 为pod提供代理，为service提供集群内部的服务发现和负载均衡，service可以看作一组提供相同服务的Pod的对外访问接口

##### 部署yaml文件

```yaml
apiVersion: v1 
kind: Pod 
metadata: 
  name: user-service 
  labels: 
    name: user-service 
spec: 
  containers:                    #定义user容器，开放10086端口 
    - name: user 
      image: user 
      ports: 
        - containerPort: 10086 
      imagePullPolicy: IfNotPresent 
    - name: mysql                     #定义MySQL容器，开放3306端口 
      image: mysql-for-user 
      ports: 
        - containerPort: 3306 
      env: 
        - name: MYSQL_ROOT_PASSWORD 
          value: "123456" 
      imagePullPolicy: IfNotPresent 
    - name: redis                     #定义Redis容器，开放6379端口 
      image: redis:5.0 
      ports: 
        - containerPort: 6379 
      imagePullPolicy: IfNotPresent
```

创建并启动

```mysql
kubectl create -f user-service.yaml
```

查看pod的信息

```
kubectl get pod user-service
```

进入pod

```
kubectl exec -ti user-servise -n default -- /bin/bash
```

其他命令

```
kubectl get - 列出resources
kubectl describe - 显示resource的详细信息
kubectl logs - 打印pod中container的日志
```

##### Pod的管理

单个pod不具备自我恢复的能力，当Pod所在的Node出现问题，Pod就很可能被删除

一般使用Controller来管理Pod，controller提供创建和管理多个pod的能力，从而使得被管理的Pod具备自愈和更新的能力

以下是常见的Controller：

**Replication Controller（RC）**, 确保用户定义的Pod副本数保持不变

**ReplicaSet(RS)**,RC的升级版，在选择器的支持优于RC，RC只支持基于等式的选择器，但RS还支持基于集合的选择器

**Deployment,**在RS的基础上提供了Pod的更新能力，在Deployment配置文件中Pod template发生变化时，它能将现在集群的状态逐步更新成Deployment中定义的目标状态

**StatefulSets**, 其中的pod是有序部署和具备稳定的标识，是一组存在状态的Pod副本

```yaml
apiVersion: v1 
kind: Deployment
metadata: 
  name: user-service 
  labels: 
    name: user-service 
spec: 
	replicas: 3
	selector:
		matchLabels:
			name: user-service
  template:
  	metadata:
  		labels:
  			name: user-service
    spec:
      containers:                    #定义user容器，开放10086端口 
        - name: user 
          image: user 
          ports: 
            - containerPort: 10086 
          imagePullPolicy: IfNotPresent 
        - name: mysql                     #定义MySQL容器，开放3306端口 
          image: mysql-for-user 
          ports: 
            - containerPort: 3306 
          env: 
            - name: MYSQL_ROOT_PASSWORD 
              value: "123456" 
          imagePullPolicy: IfNotPresent 
        - name: redis                     #定义Redis容器，开放6379端口 
          image: redis:5.0 
          ports: 
            - containerPort: 6379 
          imagePullPolicy: IfNotPresent
```

#### 8.服务注册与发现







## 设计模式

贫血模型:

充血模型:

## 系统设计

其实就是围绕业务实现，容灾方案，模块化设计，服务监控这几方面说就行

1.某航班只有一张票，有1w个人来打开网站来买票

1w的并发量数据库本来就扛不住，需要限流来避免压垮mysql服务器

不考虑幂等性:

利用mysql数据库本身的更新的粒度锁，不需要加任何锁，条件上加 num > 0就好

考虑幂等性：（乐观理念）

采用设置代替更新的做法，再添加冗余字段version来控制数据版本

2.股票交易系统，银行系统，大数据量怎么考虑

#### 共识算法

#### Raft

