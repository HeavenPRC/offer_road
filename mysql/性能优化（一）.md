## 索引的应用

### 普通索引和唯一索引的选择

#### 查询过程

效率上唯一索引稍微微优于普通索引，B+树上数据读取按页读， 再在页上做二分查找

#### 更新过程

##### change buffer

change buffer: 当需要一个数据页时，如果数据页在内存中直接更新，而如果数据页不在内存中，不影响数据一致性的前提下，innoDB会将这些更新操作缓存在change buffer中。change buffer是可以持久化的，叫做merge。

触发merge的行为：

* 访问到和数据相关的数据页面
* 后台线程定期merge
* 数据库正常关闭过程

对于唯一索引，所有更新都要判断操作是否违反约束，需要把数据页读入内存才能判读，所以不需要change buffer。因此只有普通索引使用。

change buffer使用的是buffer pool里的内存·

````
innodb_change_buffer_max_size #来动态设置
````

* 当记录在buffer pool中，差别仅仅是一个判断（因为索引数据都是有序储存）
* 当记录不在buffer pool中，唯一索引就多了一个读磁盘IO操作，普通索引直接放入change buffer

##### change buffer使用场景

change buffer 适用于写多读少的库，merge前change buffer中数据越多收益越大，读频繁的反而会增加change buffer的维护成本

##### change buffer和redo log

![avatar](https://static001.geekbang.org/resource/image/98/a3/980a2b786f0ea7adabef2e64fb4c4ca3.png)

![avatar](https://static001.geekbang.org/resource/image/6d/8e/6dc743577af1dbcbb8550bddbfc5f98e.png)

Redo log主要节省的是随机写磁盘的IO消耗，change buffer主要节省的则是随机读磁盘的IO消耗

#### 选择和应用

* 性能角度考虑，尽量选择普通索引

* 所有更新后面都跟着数据的查询，应该关闭change buffer

* 如果读少的库，change buffer应该火力全开，最大是buffer pool的50%

  

### 数据库选择索引的机制

优化器判断因素：

#### 扫描行数

* 一个索引上不同的值越多，这个索引的区分度就越好。一个索引上不同值的个数叫做**基数**

* mysql通过采样随机取出N个数据页进行分析，然后进行计算。
* 当变更数据行操作1/M的时候，会自动触发统计
* 回表

```
# on 统计信息持久储存 N 20 M 10
# off 储存在内存中 N 8 M 16
innodb_stats_persistent [on|off]
```

有时侯对扫描行树错误的判断，会导致优化器选择索引错误。

```
全表扫描聚集索引的数据行数
普通索引 show table status
```

#### 是否使用临时表

#### 是否排序

临时表>排序>扫描行数

 解决方案

* Force index 强制选择索引
* analyze # 重新统计扫描行数
* 修改语句改变mysql的索引使用
* 新建一个合适的索引或者删掉不用的索引

## flush脏页

**脏页：**和磁盘数据页内容不一致的内存数据页

**干净页：**和磁盘数据内容一致的叫做干净页

在flush脏页时，数据库就有可能会变慢

### 触发flush的场景

1.redo log已经写满

2.系统内存不足，需要淘汰掉一部分内存页，如果淘汰掉的内存页时脏页，就需要把数据刷到磁盘中

3.数据库正常关闭

### 刷脏页影响性能的情况

* 一个查询要淘汰掉的脏页个数太多，会导致查询的响应时间明显变长
* 日志写满，更新会全部堵住，写性能为0ß

### InnoDB刷脏页的控制策略

1.正确告诉innodb磁盘读写能力

```
innodb_io_capacity # 用来通知innoDB 磁盘的读写能力
```

测试磁盘读写能力的命令·：

```
fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 
```

2.不要让脏页比例靠近75%

3.相邻数据页时脏页页会被刷掉,可以通过以下参数控制行为

```
innodb_flush_neighbors 0 表示只刷自己
```

## 表空间回收（表空间压缩）

表数据可以放在共享表空间也可以是.ibd为后缀的文件

```
Innodb_fike_pre_table  # on 默认配置文件存储 off 共享表空间
```

删除表 文件储存会直接删除 但是表空间不会立即回收

### 数据删除流程

**行删除时**，不会删掉只会标记行为删除，新增对应位置的数据可能会复用这个位置。磁盘文件的大小并不会缩小。

行的复用只局限于符合范围条件的数据

**页删除时**，整个数据页可以被复用

可以复用于任何位置

当相邻的两个数据页利用率太小，数据会合并到一个数据页上，另外一个数据页标记为可复用

**删除整个表数据**，所有的数据页被标记为可用，磁盘文件并不会变小

### 数据插入流程

如果数据插入是顺序插入的，那么必然就是紧凑的不会有问题。如果是随机写入数据，就有可能造成数据页分裂。

#### 重建表

可以通过

```
alter tabke A engine=InnoDB #这里的MDL锁已经退化成读锁
```

命令来重建表,来进行空间收缩

#### Online DDL （写锁不阻塞数据操作）

流程

1.建立临时文件，扫描表A主键的所有数据页

2.用页表A的记录生成B+树，存储到临时文件中

3.生成临时文件的过程中，将所有对A的操作记录在一个日志文件中

4.临时文件生成后,将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件

5.用临时文件替换原有数据



```
alter table t engine=innodb,ALGORITHM=inplace; # 内部拷贝， server  不可见

alter table t engine=innodb,ALGORITHM=copy; #  临时表拷贝
```

1.DDL. online 一定是inlpace

2.inplace 不一定是online



#### 三种重建表方式的区别

1.alter table t engine=innodb 上面流程

2.analyze table 对索引信息进行统计 MDL读锁

3.optimize table t = 1+2

## count 的优化

innoDB 需要把数据一行一行地从引擎里面读出来，然后累积计数（这样是因为MVCC）

**count(*) mysql会找到一颗最小的树来进行遍历**

总之count操作一定会存在性能问题，解决方案

1.用缓存系统保存计数

2.用数据库保存计数(用事务关联推荐，从并发角度讲，更新记录的语句应放在后面-行锁)

 **count(*)，count(主键ID)，count(1) 都表示返回满足条件的结果集总数**

**count(字段)，返回满足条件并且不为NULL的总个数**

count(*),count(1)不取值只统计行数

**效率对比：**

**count(*)~count(1)>count(id)>count(字段)**

## order by

### 当数据无序时：

explain中Extra字段Using filesort代表需要排序，mysql会给每个线程分配一块内存用于排序（**sort buffer**）

#### 执行流程：

1.初始化sort_buffer,确实放入select中的字段

2.取出where 条件相关的第一条记录

3.从索引中取出行，取出select和order by的字段，存入sort_buffer中

4.取出where 条件相关的下一条记录

5.重赋3 4直到city的值直到不满足查询条件为止

6.对sort_buffer中的数据按照字段进行快速排序

7.按照排序结果取前1000行返回给客户端

排序动作，如果**sort_buffer_size**满足排序所需内存，就在内存中完成，反之利用磁盘临时文件辅助排序。

#### 确认是否用到了临时文件

```
/* 打开optimizer_trace，只对本线程有效 */
SET optimizer_trace='enabled=on'; 

/* @a保存Innodb_rows_read的初始值 */
select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 执行语句 */
select city, name,age from t where city='杭州' order by name limit 1000; 

/* 查看 OPTIMIZER_TRACE 输出 */
SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G

/* @b保存Innodb_rows_read的当前值 */
select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 计算Innodb_rows_read差值 表示扫描的行数 */
select @b-@a;
```

通过查看OPTIMIZER_TRACE的结果来确认，可以从**number_of_tmp_files**中看到

![avatar](https://static001.geekbang.org/resource/image/89/95/89baf99cdeefe90a22370e1d6f5e6495.png)

**Number_of_temp_flie** 表示排序用到的临时文件数，有12个（数据越大份数越多）是因为外部排序使用归并排序，每一份单独排序后再合并成一个有序的大文件。

**examined_rows**:表示参与排行的行数

**sort_mode**: 其中packed_additional_fileds  表示对字段做了紧凑处理即按实际长度处理。例如char[20]

#### rowid排序-排序单行长度太长，字段太多

长度界限:

```
SET max_length_for_sort_data = 16
```

长度太长时容易导致内存放不下；

这时mysql就会只放入主键ID和需要排序的字段，最后从原表中取出剩余字段



#### 原则：内存足够大就尽量使用内存，避免使用磁盘排序

### 有序：

1.排序字段索引时有序的

2.使用覆盖索引避免回表

## 随机排序 order by rand()

全字段都要排序，极有可能选择rowid方式进行排序。为了有更多的字段在内存中排序。

例子：表words 字段 ID word,有1w行数据

1.创建临时表（memory）,第一个字段w是double类型，第二个r是varchar(64).这个表无索引 

2.从words表中，按主键顺序取出所有的word值。对于每一个word值，调用rand()函数生成一个大于0小于1的随机数，并把随机小数分别存入w r  1w行扫描

3.按照字段R排序

4.初始化sort_buffer

5.从内存临时表一行一行取出R的值和位置信息，分别存入sort_buffer中的两个字段里。这个过程要对内存临时表进程全表扫描 2w行扫描

6.sort_buffer对R进行排序

7.排序完成取前三个

```
# Query_time: 0.900376  Lock_time: 0.000347 Rows_sent: 3 Rows_examined: 20003
SET timestamp=1541402277;
select word from words order by rand() limit 3;
```

**order by rand()**:使用的内存临时表，内存临时表排序的时候使用了rowid排序方法

## 临时表（内存临时表，磁盘临时表）

```
tmp_table_size 限制了内存临时表的大小，默认值是16m
```

如果临时表超过了这个值就会转换为磁盘临时表，默认引擎是innodb

```
internal_tmp_disk_storage_engine 控制磁盘临时表使用的引擎
```

（过程忽略不看，有时间补上）

替换方案：用主键做一个区别范围的Rand数，然后取不小于第一个id的行