## OS

#### 1.五种IO模型

阻塞IO，非阻塞IO，IO多路复用，信号驱动式IO，异步非阻塞IO

**阻塞IO**：如果accept队列为空，导致用户进程sleep，交出cpu，发生进程间切换

**非阻塞IO**：如果accept队列为空，内核收到系统调用，再收到进程的read操作后，未完成不会阻塞会返回一个error；用户进程需要不断的主动询问kernel数据准备好了没有；不会交出CPU，造成严重的资源耗费

**IO多路复用：**select，poll，epoll 一个线程保存多个socket，轮询监控读写IO。虽然会发生阻塞但不会阻塞在io上，是阻塞在函数上。一个socket的阻塞不会影响其他的socket的Io读写。

最大的优势是：一个用户线程监控多个socket io

**信号驱动式IO：**首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，用户进程再调用I/O操作函数处理数据。

**异步非阻塞IO：**异步IO不是顺序执行。`用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情`。等到socket数据准备好了，内核直接复制数据给进程无序用户进程调用IO操作，`然后从内核向进程发送通知`。`IO两个阶段，进程都是非阻塞的`。

#### 2.select/poll/epoll的区别

|              | select                                                       | poll                   | epoll                                       |
| ------------ | ------------------------------------------------------------ | ---------------------- | ------------------------------------------- |
| 打开句柄数量 | 句柄集合是一个数组，调用select需要全部拷贝，内核做了限制1024 | 用链表储存没有大小限制 | 一个文件描述符管理多个描述符,数量远大于1024 |
| 内存         | 每次调用select，都需要把`fd_set`集合从用户态拷贝到内核       | 和select一样           | Mmap内存映射和内核共用一块内存              |
| 操作         | 内核要对所有fd_set进行遍历，如果`fd_set`集合很大时，那这个开销也很大， | 和select一样           | 活跃的socket才会触发                        |

#### 3. 进程，线程和协程

##### 进程

进程是系统分配资源的最小单位，所以进程和进程间的内存是相互隔离的并不共享。在进程未占用处理器时，进程 的上下文是存储在进程的私有[堆栈](https://baike.baidu.com/item/堆栈)中的；切换时要保存当前进程的上下文；所以频繁切换进程需要整理一大段内存空间来保存未执行完的进程现场，等下次轮到 CPU 时间片再恢复现场进行运算。频繁切换会带来大小的资源消耗。

##### 线程（内核级线程）

由内核进行调度，共享进程的内存空间，切换自然；但是数量过多会对内核的调度器带来不小的负担，甚至拖垮整体性能。

##### 协程（用户级线程）

是一个特殊的用户函数，可以挂起和恢复运行，完全由用户程序来进行调度，但是在一个线程内并不能并发执行，只能是线性，这就意味着只要有一个阻塞占用CPU资源就会造成所有线程的阻塞。想并发还得依靠多个线程。但是胜在内存共享，切换成本极低。

#### 4.线程模型

* 用户级线程 1:N
* 内核级线程 1:1
* 两极线程模型 M:N

## 网络

#### 1. 常用状态码

301 永久重定向

302 重定向，禁止缓存

304  （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。

401（未授权） 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应

403  （禁止） 服务器拒绝请求。-权限校验

412  （未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。

413  请求实体过大

500 服务内部发生错误-服务发生错误

502 与上游未成功建立连接

503 服务暂时不可用-发生在nginx限流

#### 2. TCP三次握手

客户端主动发起请求会发送一个SYN报文初始序号seq这就是第一次握手，服务器收到后返回一段SYN,ACK报文以及带着自己的初始序列号这是第二次握手，最后客户端返回一个ACK 确认收到收到初始序列号。

##### 不是两次握手的原因

双方都需要确认对方的初始序列号，所以在保证消耗资源最小和保证安全的前提下3次最合适

##### 不主动关闭连接的保活

TCP设有一个保活计时器，服务器每收到一次客户端的请求都会重新复位这个计时器，时间通常设置为两小时，如果两个小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，每隔75秒发送一次。如果一连发送10个探测报文仍然没有反应，服务器认为客户端出了故障，接着就关闭连接

#### 4.TCP 关闭连接的四次挥手

第一次挥手:发送一个FIN带着自己序号seq，表示想要断开连接，进入FIN_WAIT_1（半关闭状态）

第二次挥手:服务器收到后离开ESTABLISHED状态，进入close_wait, 返回ACK 确认自己收到了关闭的请求并检查自己是否还有数据要发送给主动方，客户端进入FIN-WAIT-2

第三次挥手:服务器开始向客户端发送FIN，ACK(表示在收到客户端报文的基础上+1)表示已经准备好释放连接，进入last-ack

第四次挥手:  客户端发送ACK表示收到，进入TIME_WAIT

##### 为什么是四次

服务器接收到请求后，有可能还有未处理完成的请求。

和握手一样是基于seq和ack来做的，双方都需要知道对方收到自己的请求，一但都是报文流程就不可继续

##### 为什么要time_wait等待2MSL（max segment lifetime一段TCP报文在传输过程中的最长生命周期）

这是一个保底机制，最后一次挥手客户端不确定服务器会不会收到报文。

而服务器在1MSL内没有收到ACK报文，就会向客户端重新发送一个ACK报文

#### 3. TCP的状态

**CLOSED**：初始状态，表示TCP连接是“关闭着的”或“未打开的”。

**LISTEN** ：表示服务器端的某个SOCKET处于监听状态，可以接受客户端的连接。

**SYN_RCVD** ：表示服务器接收到了来自客户端请求连接的SYN报文。在正常情况下，这个状态是服务器端的SOCKET在建立TCP连接时的三次握手会话过程中的一个中间状态，很短暂，基本上用netstat很难看到这种状态，除非故意写一个监测程序，将三次TCP握手过程中最后一个ACK报文不予发送。当TCP连接处于此状态时，再收到客户端的ACK报文，它就会进入到ESTABLISHED 状态。

**SYN_SENT** ：这个状态与SYN_RCVD 状态相呼应，当客户端SOCKET执行connect()进行连接时，它首先发送SYN报文，然后随即进入到SYN_SENT 状态，并等待服务端的发送三次握手中的第2个报文。SYN_SENT 状态表示客户端已发送SYN报文。

**ESTABLISHED** ：表示TCP连接已经成功建立。

**FIN_WAIT_1** ：这个状态得好好解释一下，其实FIN_WAIT_1 和FIN_WAIT_2 两种状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：

FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET进入到FIN_WAIT_1 状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2 状态。当然在实际的正常情况下，无论对方处于任何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1 状态一般是比较难见到的，而FIN_WAIT_2 状态有时仍可以用netstat看到。

**FIN_WAIT_2** ：上面已经解释了这种状态的由来，实际上FIN_WAIT_2状态下的SOCKET表示半连接，即有一方调用close()主动要求关闭连接。注意：FIN_WAIT_2 是没有超时的（不像TIME_WAIT 状态），这种状态下如果对方不关闭（不配合完成4次挥手过程），那这个 FIN_WAIT_2 状态将一直保持到系统重启，越来越多的FIN_WAIT_2 状态会导致内核crash。

**TIME_WAIT** ：表示收到了对方的FIN报文，并发送出了ACK报文。 TIME_WAIT状态下的TCP连接会等待2*MSL（Max Segment Lifetime，最大分段生存期，指一个TCP报文在Internet上的最长生存时间。每个具体的TCP协议实现都必须选择一个确定的MSL值，RFC 1122建议是2分钟，但BSD传统实现采用了30秒，Linux可以cat /proc/sys/net/ipv4/tcp_fin_timeout看到本机的这个值），然后即可回到CLOSED 可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（这种情况应该就是四次挥手变成三次挥手的那种情况）

**CLOSING** ：这种状态在实际情况中应该很少见，属于一种比较罕见的例外状态。正常情况下，当一方发送FIN报文后，按理来说是应该先收到（或同时收到）对方的ACK报文，再收到对方的FIN报文。但是CLOSING 状态表示一方发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什么情况下会出现此种情况呢？那就是当双方几乎在同时close()一个SOCKET的话，就出现了双方同时发送FIN报文的情况，这是就会出现CLOSING 状态，表示双方都正在关闭SOCKET连接。

**CLOSE_WAIT** ：表示正在等待关闭。怎么理解呢？当对方close()一个SOCKET后发送FIN报文给自己，你的系统毫无疑问地将会回应一个ACK报文给对方，此时TCP连接则进入到CLOSE_WAIT状态。接下来呢，你需要检查自己是否还有数据要发送给对方，如果没有的话，那你也就可以close()这个SOCKET并发送FIN报文给对方，即关闭自己到对方这个方向的连接。有数据的话则看程序的策略，继续发送或丢弃。简单地说，当你处于CLOSE_WAIT 状态下，需要完成的事情是等待你去关闭连接。

**LAST_ACK** ：当被动关闭的一方在发送FIN报文后，等待对方的ACK报文的时候，就处于LAST_ACK 状态。当收到对方的ACK报文后，也就可以进入到CLOSED 可用状态了。

#### 4. TIME_WAIT的问题

在高并发场景下，在短时间内业务处理+传输数据的时间远小于TIME_WAIT的时间，导致会有大量的端口被占用导致服务器拒绝为一部分客户服务。

编辑内核文件/etc/sysctl.conf

```
net.ipv4.tcp_syncookies = 1 表示开始SYN cookies, 当SYN等待队列溢出时，启用cookie来处理，可防范少量SYN攻击
net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认0，表示关闭
net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收 默认为0 表示关闭
net.ipv4.tcp_fin_timeout 修改系统默认的TIMEOUT时间
```

```
系统保存TIME_WAIT套接字的最大数量
```

#### 5.tcp和udp的区别

TCP通信协议

- TCP是面向连接的；
- 每条TCP连接只能由于两个端点，一对一通信；
- TCP提供可靠的交付服务，传输数据无差错，不丢失，不重复，且按时序到达；
- TCP提供全双工通信；
- 面向字节流，TCP根据对方给出的窗口和当前的网络拥塞程度决定一个报文应该包含多少个字节。

UDP通信协议

- 无连接；
- UDP使用尽最大努力交付，不保证可靠性UDP是面向报文的，UDP对应用层交付下来的报文，既不合并，也不拆分，而是保留报文的边界；
- 应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文；
- UDP没有拥塞控制；
- UDP支持一对一，一对多，多对一和多对多的交互通信。
- UDP的首部开销小，只有8字节。

#### 6.http(1 |1.1|2|3)的区别

##### http1.1  

1. TCP 连接复用-keep-alive

2. 请求需要满足**先进先出的队列顺序**：发送请求--等待响应，再发送下一个请求。HTTP/1.1允许多个http请求通过一个套接字同时被输出 ，而不用等待相应的响应。然后请求者就会等待各自的响应，这些响应是按照之前请求的顺序依次到达。（所有请求保持一个FIFO的队列，一个请求发送完之后，不必等待这个请求的响应被接受到，下一个请求就可以被再次发出；同时，服务器端返回这些请求的响应时也是按照FIFO的顺序）。- 这也叫队首阻塞

   由于TCP严格按照按顺序交付，丢失一个TCP分组就会阻塞所有高序号的分组，除非重传丢失的分组，这也会带来额外的延迟。由于HTTP1.1中不允许多路复用，HTTP管道也会带来一些不容忽视的问题：

   一个慢响应会阻塞所有后续请求；

   并行处理请求时，服务器需要缓存处理结果，会占用服务器资源，如果某个响应很大，很容易形成服务器的受攻击面；

   响应失败可能终止TCP连接，会强迫客户端重新发送对后续资源的请求，导致重复处理；

   网络环境中存在中间代理，检测管道兼容性十分必要；

   如果中间代理不支持管道，那它可能中断连接，也可能把所有请求串联起来。

   正是由于存在这样或那样的问题，HTTP管道技术的应用比较有限，并没有大面积推广开来，即使一些支持它的浏览器也仅仅把它作为一个高级选项。如果你对客户端和服务端都有很强的控制力，依然可以使用它，会带来不错的性能提升。

   优化：

   * 使用多个TCP连接

     **优点**：

     客户端可以并行发起多个请求；

     服务器可以并行处理多个请求；

     第一次往返可以发送的累计分组数量是原来的6倍；

     **缺点**：

     更多的套接字会占用更多的资源；

     并行TCP流之间竞争共享的带宽；

     处理多个套接字，实现更为复杂；

     即使并行TCP流，应用的并发能力也受限制。

     这种打开多个连接的方式，也带来了一些坏处，那为什么现在还使用的如此广泛呢？主要由以下三个原因:

     作为绕过HTTP限制的一个权宜之计；

     作为绕过TCP中低起始拥塞窗口的一个权宜之计；

     作为客户端绕过不能使用TCP窗口缩放的一个权益之计。

   * 域名分区绕一下：将N个域名指向同一台服务器上

3. 增强的缓存机制 没修改返回一个304 有改动返回一个200

4. **分块编码传输**

5. Host头域

6. **请求方式新增**

7. **带宽优化**

##### http2.0

在语义上保证稳定，语法上达到阔斧；仍然使用http和https；

* 优化了大头儿子header，头很大但是身体很小

  使用HPACK算法，在客户端和服务器两端建立“字典”，用索引号表示重复的字符串，还采用哈夫曼编码来压缩整数和字符串，可以达到50%～90%的高压缩率

* 二进制格式

  将原来的header+body的消息打散为数个小片的二进制帧，用headers帧存放头数据，data帧存放实体数据

* 虚拟流（可以看作http1的请求和响应）

  是一个二进制帧的双向传输序列，同一个消息往返的帧会分配一个唯一的流id。按照顺序组装起来就是就是请求和响应

* 多路复用

  HTTP/2可以在一个TCP连接上用“流”同时发送多个碎片化的消息--多个往返通信都复用一个TCP连接；

  在流层面是有序的

  在连接层面，消息乱序收发，多个请求和响应没有了顺序关系，所以也没有了队头阻塞。

* 服务器推送

  改变了传统意义上的“请求-应答”，服务器可以主动的新建一个流主动向客户端发送消息。（比如主动推送一些css和js）

* 强化了安全，将一些加密协议从白名单移除；通信协议需要在TLS1.2以上

##### http3

TCP为了保证有序性和完整性，当网络不好时，有个一个包未到达都会卡在TCP缓冲里。这就是TCP的队头阻塞。



#### 7.https

安全特性：机密性，完整性，身份认证，不可否认

在http和tcp/ip之间加了一层ssl/tls

密码套件：“密钥交换算法+签名算法+对称加密算法+摘要算法”

TLS 密钥交换使用非对称加密，之后的全部使用对称加密

数字签名生成数据摘要-SHA-2算法

#### 8.HPACK

静态表和动态表

## 数据结构（融化于各个细节中）

## 算法

## Nginx

#### 1.nginx如何处理一个请求

首先，nginx在启动时，会解析配置文件，得到需要监听的端口与ip地址，然后在nginx的master进程里面，先初始化好这个监控的socket(创建socket，设置addrreuse等选项，绑定到指定的ip地址端口，再listen)，然后再fork(一个现有进程可以调用fork函数创建一个新进程。由fork创建的新进程被称为子进程 )出多个子进程出来，然后子进程会竞争accept新的连接。此时，客户端就可以向nginx发起连接了。当客户端与nginx进行三次握手，与nginx建立好一个连接后，此时，某一个子进程会accept成功，得到这个建立好的连接的socket，然后创建nginx对连接的封装，即ngx_connection_t结构体。接着，设置读写事件处理函数并添加读写事件来与客户端进行数据的交换。最后，nginx或客户端来主动关掉连接，到此，一个连接就寿终正寝了。

　　当然，nginx也是可以作为客户端来请求其它server的数据的（如upstream模块），此时，与其它server创建的连接，也封装在ngx_connection_t中。作为客户端，nginx先获取一个ngx_connection_t结构体，然后创建socket，并设置socket的属性（ 比如非阻塞）。然后再通过添加读写事件，调用connect/read/write来调用连接，最后关掉连接，并释放ngx_connection_t。

　　nginx在实现时，是通过一个连接池来管理的，每个worker进程都有一个独立的连接池，连接池的大小是worker_connections。这里的连接池里面保存的其实不是真实的连接，它只是一个worker_connections大小的一个ngx_connection_t结构的数组。并且，nginx会通过一个链表free_connections来保存所有的空闲ngx_connection_t，每次获取一个连接时，就从空闲连接链表中获取一个，用完后，再放回空闲连接链表里面。

　　在这里，很多人会误解worker_connections这个参数的意思，认为这个值就是nginx所能建立连接的最大值。其实不然，这个值是表示每个worker进程所能建立连接的最大值，所以，一个nginx能建立的最大连接数，应该是worker_connections * worker_processes。当然，这里说的是最大连接数，对于HTTP请求本地资源来说，能够支持的最大并发数量是worker_connections * worker_processes，而如果是HTTP作为反向代理来说，最大并发数量应该是worker_connections * worker_processes/2。因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。

## mysql



## Redis

##### 1.Redis 缓存具体是怎么工作的？
##### 2.Redis 缓存如果满了，该怎么办？
##### 3.为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？
##### 4.Redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那么，Redis 缓存可以使用快速固态硬盘吗？

##### 5.Redis连接过高有1w个连接

有可能是大量socket连接之后迅速关闭造成的。

1.redis默认可以打来1w的连接，修改相关配置项,然后平滑重启

```
cd /usr/local/redis/bin 必须进入bin文件
./redis-server /usr/local/redis/etc/redis.conf  配置文件来启动Redis 服务
./redis-cli 启动客服端
127.0.0.1:6379>这个就代表进来了
debug reload 平滑重启
如果有密码就输入密码，密码忘记了就去Redis配置文件找
```

2.查看是否时空闲连接过多不释放

查看链接状态

```
redis-cli client list

addr=127.0.0.1:52555 fd=5 name= age=855 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client
addr=127.0.0.1:52787 fd=6 name= age=6 idle=5 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=ping
```

查看配置

```
redis-cli config get timeout
```

配置空闲清理

```
redis-cli config set timeout 600
```

3.修改业务代码使用连接池，避免每一个命令打开一个连接或者使用完后主动关闭

## Go&PHP

#### 1.GMP

M:工作线程和内核线程一一绑定

P:上线文

G:一个go函数，用户级线程

M与P是一对一的关系，经过调度也会进行P的切换，每个P下面有两个G队列， 一个是可运行G队列和运行完成的G队列；

但是P和M的数量不一定是相等的，当M由于系统调用发生阻塞，P下面的可运行G队列未空是会解绑的，会找到一个空闲的G或者新创建一个M

runtime 全局G,M,P链表 

sched 调度器空闲P

​            调度器空闲G

​            调度器可运行G队列 环型队列

​			调度器两个自由G（有栈和无栈），为了复用都是空栈

​			本地运行G队列 上限256个的环型队列,满了之后会将其中的一半转移到全局可运行G队列中

​			本地自由G队列

##### 调度流程:

创建主G，调度中M与它绑定，后面执行

- 启动监控进程（由一个特殊的M执行）。
- 调用runtime的初始化函数。
- 开启gc。
- 调用main的初始化函数。
- 调用main.main，执行完后退出

##### 其中调度的流程为下：（运行在若干个M中，G的阻塞结束退出系统调用都会触发）

* 检查当前的M的绑定情况
  * 绑定则挂起并且停止调度
  * 没有绑定
* 判断有没有painc或者GC需要停止调度
* 开始寻找可运行的G
  * 全局可运行G，本地P
  * GC标记阶段的G
  * 从其他p中偷取G

* 有就看看有没有与M绑定，
  * 如果已绑定就唤醒
  * 执行

##### 系统监控干了啥

> 抢夺P和G: 

​	把可运行G放入全局可运行列表中；

​	通过网络IO轮询器获取可运行的G（即得到netpoller通知的G）；前提条件是以经过10ms没有按照此图径抢夺

​	从调度器里抢夺符合条件的G；

​	抢夺流程：

 * 判断P自身和系统监控的调用技术是否相同，相同就继续向下判断，不同更新备份并跳过

 * P处于Pruning和Psyscall

 * Psyscall:是否有必要抢夺P；P的G队列已空，有M处于自旋

   如果有符合条件的P，然后把P转给其他M

 * Pruning:超过10ms，发通知给G运行时间太长只负责发

> 是否强制GC,，唤醒GC的G

> 打印调度跟踪信息

#### 2.channle

共享信息的实现,原子操作。

#### 3.GC

##### 系统监测中的强制GC：

GC专用G一般处于暂停状态，只有系统监测可以恢复；

当当前GC未执行，且超过GC最大执行时间（2min），则唤醒并放入全局可运行G队列中；

清扫堆的工作只在距上次清扫时间大于最大时间间隔（5min），将最进未使用的堆内存还给操作系统；

##### 调度系统的自动GC：

多了一个条件，当占用内存有较大增量时才会触发(内存翻倍)

## 系统设计

其实就是围绕业务实现，容灾方案，模块化设计，服务监控这几方面说就行